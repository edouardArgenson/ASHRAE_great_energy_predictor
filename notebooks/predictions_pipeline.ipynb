{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import joblib\n",
    "\n",
    "from os import path\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted, column_or_1d\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_val_predict\n",
    "\n",
    "from tscv import GapKFold\n",
    "\n",
    "from time import time, localtime, strftime\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_time_id = '20200328_173456'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../data/raw/csvs/test.csv', parse_dates=['timestamp'])\n",
    "test_df.set_index('row_id', inplace=True) # (in two steps to avoid a warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  meter  timestamp\n",
       "row_id                               \n",
       "0                 0      0 2017-01-01\n",
       "1                 1      0 2017-01-01\n",
       "2                 2      0 2017-01-01\n",
       "3                 3      0 2017-01-01\n",
       "4                 4      0 2017-01-01"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41697600 entries, 0 to 41697599\n",
      "Data columns (total 3 columns):\n",
      "building_id    int64\n",
      "meter          int64\n",
      "timestamp      datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(2)\n",
      "memory usage: 1.2 GB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve training directory path\n",
    "\n",
    "base_directory_path = '../models/test/'\n",
    "timed_base_folder_name = 'trained_models_' + training_time_id\n",
    "training_folder_path = path.join(base_directory_path, timed_base_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n- prepare each site weather data\\n\\n- get each building site\\n\\n- (for tests only) clean building list, keep only buildings for which we saved a model (using training_infos.csv)\\n\\n- for all meters\\n    load and predict\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "- prepare each site weather data\n",
    "\n",
    "- get each building site\n",
    "\n",
    "- (for tests only) clean building list, keep only buildings for which we saved a model (using training_infos.csv)\n",
    "\n",
    "- for all meters\n",
    "    load and predict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Prepare and cache each site weather data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_site_data(data_folder_path):\n",
    "    \n",
    "    # Loads weather data\n",
    "    raw_df_weather = pd.read_csv(path.join(data_folder_path, 'weather_test.csv'), \n",
    "                     parse_dates=['timestamp'], index_col=['site_id', 'timestamp'])\n",
    "    \n",
    "    # Get site list\n",
    "    site_list = raw_df_weather.index.get_level_values('site_id').unique().tolist()\n",
    "    prepared_site_data = {}\n",
    "    \n",
    "    for site in site_list:\n",
    "        prepared_site_data[site] = prepare_site_data(raw_df_weather, site)\n",
    "        \n",
    "        \n",
    "    return prepared_site_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For test set we also perform linear extrapolation (contrary to train).\n",
    "\"\"\"\n",
    "def prepare_site_data(weather_df, site_id):\n",
    "    \n",
    "    b_df_weather = weather_df.loc[(site_id,)]\n",
    "\n",
    "    # keep only air_temperature and dew_temperature\n",
    "    b_df_weather.drop(\n",
    "        ['precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed', 'cloud_coverage'],\n",
    "        axis=1,\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    # Clean timestamps index.\n",
    "    clean_index = pd.date_range(start=b_df_weather.index.min(), end=b_df_weather.index.max(), freq='H')\n",
    "    b_df_weather = b_df_weather.reindex(index=clean_index, copy=True)\n",
    "\n",
    "\n",
    "    # Interpolate missing values.\n",
    "    b_df_weather.interpolate(method='linear', limit=3, inplace=True)\n",
    "    \n",
    "    # Build time features\n",
    "    b_df_weather['day_hour'] = b_df_weather.index.to_series().dt.hour\n",
    "    b_df_weather['day_of_week'] = b_df_weather.index.to_series().dt.dayofweek\n",
    "\n",
    "    # Builds averaged weather features.\n",
    "\n",
    "    timeframes = [24]\n",
    "    features_to_avg = ['air_temperature', 'dew_temperature']\n",
    "    do_center = False\n",
    "\n",
    "    for c in features_to_avg:\n",
    "        ts = b_df_weather[c]\n",
    "        for timeframe in timeframes:\n",
    "            shifted_ts = ts.rolling(timeframe, center=do_center).mean()\n",
    "            new_col_name = '' + c + '_ma_' + str(timeframe) + 'H'\n",
    "            # Extrapolate missing values (specific to test set preparation)\n",
    "            extrapolated_shifted_ts = shifted_ts.interpolate(\n",
    "                method='linear',\n",
    "                limit_direction='backward', \n",
    "                limit_area='outside', \n",
    "                inplace=False\n",
    "            )\n",
    "            b_df_weather[new_col_name] = extrapolated_shifted_ts\n",
    "            \n",
    "            \n",
    "    # Drops rows with NaNs.\n",
    "    b_df_weather.dropna(axis=0, how='any', inplace=True)\n",
    "            \n",
    "    print('shape={}'.format(b_df_weather.shape))\n",
    "        \n",
    "    return b_df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape=(17520, 6)\n",
      "shape=(17183, 6)\n",
      "shape=(17520, 6)\n",
      "shape=(17520, 6)\n",
      "shape=(17519, 6)\n",
      "shape=(17124, 6)\n",
      "shape=(17494, 6)\n",
      "shape=(16368, 6)\n",
      "shape=(17520, 6)\n",
      "shape=(17191, 6)\n",
      "shape=(17465, 6)\n",
      "shape=(16368, 6)\n",
      "shape=(17184, 6)\n",
      "shape=(17520, 6)\n",
      "shape=(17519, 6)\n",
      "shape=(16734, 6)\n"
     ]
    }
   ],
   "source": [
    "data_folder = '../data/raw/csvs/'\n",
    "\n",
    "site_data = load_and_prepare_site_data(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Retrieve each building site</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  meter  timestamp\n",
       "row_id                               \n",
       "0                 0      0 2017-01-01\n",
       "1                 1      0 2017-01-01\n",
       "2                 2      0 2017-01-01\n",
       "3                 3      0 2017-01-01\n",
       "4                 4      0 2017-01-01"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             site_id\n",
       "building_id         \n",
       "0                  0\n",
       "1                  0\n",
       "2                  0\n",
       "3                  0\n",
       "4                  0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdata = pd.read_csv(\n",
    "    '../data/raw/csvs/building_metadata.csv', \n",
    "    index_col='building_id', \n",
    "    usecols=['building_id', 'site_id']\n",
    ")\n",
    "bdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [(0, 0), (1, 0), (2, 0), (3, 0), (4, 0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_grouped = test_df.groupby(['building_id', 'meter']).count()\n",
    "test_df_grouped = test_df.groupby(['building_id', 'meter']).count()\n",
    "test_df_grouped.drop('timestamp', axis=1, inplace=True)\n",
    "test_df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_grouped = test_df_grouped.join(bdata, on='building_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2380, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_grouped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   site_id\n",
       "building_id meter         \n",
       "0           0            0\n",
       "1           0            0\n",
       "2           0            0\n",
       "3           0            0\n",
       "4           0            0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Keep only (building, meter) for which we trained a model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training info\n",
    "training_info_path = path.join(training_folder_path, 'training_info.csv')\n",
    "\n",
    "training_info = pd.read_csv(training_info_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building</th>\n",
       "      <th>meter_id</th>\n",
       "      <th>rfr_improvement</th>\n",
       "      <th>saved_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.119602</td>\n",
       "      <td>time_avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>682</td>\n",
       "      <td>0</td>\n",
       "      <td>32.392600</td>\n",
       "      <td>rfr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>969</td>\n",
       "      <td>1</td>\n",
       "      <td>46.323085</td>\n",
       "      <td>rfr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1242</td>\n",
       "      <td>3</td>\n",
       "      <td>63.526895</td>\n",
       "      <td>rfr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>346</td>\n",
       "      <td>0</td>\n",
       "      <td>-19.987248</td>\n",
       "      <td>time_avg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   building  meter_id  rfr_improvement saved_model\n",
       "0       723         0        -9.119602    time_avg\n",
       "1       682         0        32.392600         rfr\n",
       "2       969         1        46.323085         rfr\n",
       "3      1242         3        63.526895         rfr\n",
       "4       346         0       -19.987248    time_avg"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building</th>\n",
       "      <th>meter_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   site_id\n",
       "building meter_id         \n",
       "723      0               5\n",
       "682      0               5\n",
       "969      1               9\n",
       "1242     3              14\n",
       "346      0               3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_meter_index = pd.MultiIndex.from_frame(training_info[['building', 'meter_id']])\n",
    "sub_test_df_grouped = test_df_grouped.loc[trained_meter_index]\n",
    "sub_test_df_grouped.head()                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Model functions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanByMultiCatEstimator(BaseEstimator):\n",
    "    \"\"\" A template estimator to be used as a reference implementation.\n",
    "    For more information regarding how to build your own estimator, read more\n",
    "    in the :ref:`User Guide <user_guide>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    demo_param : str, default='demo_param'\n",
    "        A parameter used for demonstation of how to pass and store paramters.\n",
    "    \"\"\"\n",
    "    def __init__(self, cat_column_indexes=[0], verbose=False):\n",
    "        self.verbose = verbose\n",
    "        self.cat_column_indexes = cat_column_indexes\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"A reference implementation of a fitting function.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        y : array-like, shape (n_samples,) or (n_samples, n_outputs)\n",
    "            The target values (class labels in classification, real numbers in\n",
    "            regression).\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        \n",
    "        X, y = check_X_y(X, y, accept_sparse=True)\n",
    "        \"\"\"Input validation for standard estimators.\n",
    "        Checks X and y for consistent length, enforces X to be 2D and y 1D. By\n",
    "        default, X is checked to be non-empty and containing only finite values.\n",
    "        Standard input checks are also applied to y, such as checking that y\n",
    "        does not have np.nan or np.inf targets. For multi-label y, set\n",
    "        multi_output=True to allow 2D and sparse y. If the dtype of X is\n",
    "        object, attempt converting to float, raising on failure.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        cat_columns = []\n",
    "        \n",
    "        for col_idx in self.cat_column_indexes:\n",
    "            if(col_idx >= X.shape[1]):\n",
    "                raise ValueError(\"category column indexes should be < X.shape[1]\")\n",
    "            cat_columns.append(X[:, col_idx])\n",
    "            \n",
    "        cat_tuples = set(zip(*cat_columns))\n",
    "        \n",
    "        categories = {}\n",
    "        self.means = {}\n",
    "        \n",
    "        self.mean = y.mean()\n",
    "        \n",
    "        for x_bin in cat_tuples:\n",
    "            categories[x_bin] = []\n",
    "            \n",
    "        if self.verbose:    \n",
    "            print('categories : {}'.format(categories.keys()))\n",
    "            \n",
    "        for k in range(X.shape[0]):\n",
    "            sample_bin = tuple(X[k, self.cat_column_indexes])\n",
    "            categories[sample_bin].append(y[k])\n",
    "        \n",
    "        for k, v in categories.items():\n",
    "            self.means[k] = np.array(v).mean()\n",
    "        \n",
    "        self.is_fitted_ = True\n",
    "        # `fit` should always return `self`\n",
    "        \n",
    "        if self.verbose:\n",
    "            for k, v in self.means.items():\n",
    "                print('({}, {})'.format(k, v))\n",
    "        \n",
    "        return self\n",
    "\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\" A reference implementation of a predicting function.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        Returns\n",
    "        -------\n",
    "        y : ndarray, shape (n_samples,)\n",
    "            Returns an array of ones.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        X = check_array(X, accept_sparse=True)\n",
    "        \"\"\"Input validation on an array, list, sparse matrix or similar.\n",
    "        By default, the input is checked to be a non-empty 2D array containing\n",
    "        only finite values. If the dtype of the array is object, attempt\n",
    "        converting to float, raising on failure.\"\"\"\n",
    "        \n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        \n",
    "        cat_columns=[]\n",
    "        for col in self.cat_column_indexes:\n",
    "            cat_columns.append(X[:, col])\n",
    "            \n",
    "        cat_tuples = list(zip(*cat_columns))\n",
    "        \n",
    "        \n",
    "        \n",
    "        for sample_cat in cat_tuples:\n",
    "            cat_mean = self.means.get(sample_cat)\n",
    "            if(cat_mean == None):\n",
    "                predictions.append(self.mean)\n",
    "            else:\n",
    "                predictions.append(cat_mean)\n",
    "            \n",
    "        \n",
    "        \n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Load models and predict</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor (building, meter) in sub_test_df_grouped.index:\\n    - get site\\n    - get timestamps to predict\\n    - load model\\n    - predict\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for (building, meter) in sub_test_df_grouped.index:\n",
    "    - get site\n",
    "    - get timestamps to predict\n",
    "    - load model\n",
    "    - predict\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edouard/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-d7d43d146a8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msite_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestamps_to_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mmeter_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-ce9dc082fe2f>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \"\"\"Input validation on an array, list, sparse matrix or similar.\n\u001b[1;32m     93\u001b[0m         \u001b[0mBy\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mchecked\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mempty\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0mD\u001b[0m \u001b[0marray\u001b[0m \u001b[0mcontaining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 542\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "for (building, meter) in sub_test_df_grouped.index:\n",
    "    \n",
    "    site = sub_test_df_grouped.loc[(building, meter), 'site_id']\n",
    "    \n",
    "    this_b_and_m = (test_df['building_id']==building) & (test_df['meter']==meter)\n",
    "    timestamps_to_predict = test_df[this_b_and_m]['timestamp']\n",
    "    \n",
    "    # Load model\n",
    "    b_folder = 'building_' + str(building)\n",
    "    m_folder = 'meter_' + str(meter)\n",
    "    model_path = path.join(training_folder_path, b_folder, m_folder, 'best_model.joblib')\n",
    "    meter_model = joblib.load(model_path)\n",
    "    \n",
    "    print('site : {}'.format(site))\n",
    "    \n",
    "    x_test = site_data[site].loc[pd.Index(timestamps_to_predict)]\n",
    "    \n",
    "    meter_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>day_hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>air_temperature_ma_24H</th>\n",
       "      <th>dew_temperature_ma_24H</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:00</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 03:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 04:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 05:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 06:00:00</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 07:00:00</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 08:00:00</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 09:00:00</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 10:00:00</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 11:00:00</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 12:00:00</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 13:00:00</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 14:00:00</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 15:00:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 16:00:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 17:00:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 18:00:00</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 19:00:00</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 20:00:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 21:00:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 22:00:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 23:00:00</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02 00:00:00</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02 01:00:00</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.875000</td>\n",
       "      <td>4.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02 02:00:00</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>4.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02 03:00:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.458333</td>\n",
       "      <td>3.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02 04:00:00</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>3.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02 05:00:00</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.041667</td>\n",
       "      <td>3.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02 06:00:00</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.791667</td>\n",
       "      <td>2.958333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     air_temperature  dew_temperature  day_hour  day_of_week  \\\n",
       "timestamp                                                                      \n",
       "2017-01-01 01:00:00              9.0              7.0       1.0          6.0   \n",
       "2017-01-01 02:00:00              9.0              8.0       2.0          6.0   \n",
       "2017-01-01 03:00:00              8.0              8.0       3.0          6.0   \n",
       "2017-01-01 04:00:00              8.0              8.0       4.0          6.0   \n",
       "2017-01-01 05:00:00              8.0              8.0       5.0          6.0   \n",
       "2017-01-01 06:00:00              9.0              8.0       6.0          6.0   \n",
       "2017-01-01 07:00:00              9.0              8.0       7.0          6.0   \n",
       "2017-01-01 08:00:00              9.0              8.0       8.0          6.0   \n",
       "2017-01-01 09:00:00              9.0              8.0       9.0          6.0   \n",
       "2017-01-01 10:00:00              9.0              8.0      10.0          6.0   \n",
       "2017-01-01 11:00:00              5.0              5.0      11.0          6.0   \n",
       "2017-01-01 12:00:00              5.0              5.0      12.0          6.0   \n",
       "2017-01-01 13:00:00              5.0              4.0      13.0          6.0   \n",
       "2017-01-01 14:00:00              5.0              3.0      14.0          6.0   \n",
       "2017-01-01 15:00:00              4.0              3.0      15.0          6.0   \n",
       "2017-01-01 16:00:00              4.0              3.0      16.0          6.0   \n",
       "2017-01-01 17:00:00              4.0              3.0      17.0          6.0   \n",
       "2017-01-01 18:00:00              5.0              2.0      18.0          6.0   \n",
       "2017-01-01 19:00:00              5.0              2.0      19.0          6.0   \n",
       "2017-01-01 20:00:00              4.0              1.0      20.0          6.0   \n",
       "2017-01-01 21:00:00              4.0              1.0      21.0          6.0   \n",
       "2017-01-01 22:00:00              4.0              0.0      22.0          6.0   \n",
       "2017-01-01 23:00:00              3.0              0.0      23.0          6.0   \n",
       "2017-01-02 00:00:00              3.0              1.0       0.0          0.0   \n",
       "2017-01-02 01:00:00              3.0              1.0       1.0          0.0   \n",
       "2017-01-02 02:00:00              3.0              1.0       2.0          0.0   \n",
       "2017-01-02 03:00:00              4.0              1.0       3.0          0.0   \n",
       "2017-01-02 04:00:00              3.0              1.0       4.0          0.0   \n",
       "2017-01-02 05:00:00              3.0              1.0       5.0          0.0   \n",
       "2017-01-02 06:00:00              3.0              1.0       6.0          0.0   \n",
       "\n",
       "                     air_temperature_ma_24H  dew_temperature_ma_24H  \n",
       "timestamp                                                            \n",
       "2017-01-01 01:00:00                6.125000                4.666667  \n",
       "2017-01-01 02:00:00                6.125000                4.666667  \n",
       "2017-01-01 03:00:00                6.125000                4.666667  \n",
       "2017-01-01 04:00:00                6.125000                4.666667  \n",
       "2017-01-01 05:00:00                6.125000                4.666667  \n",
       "2017-01-01 06:00:00                6.125000                4.666667  \n",
       "2017-01-01 07:00:00                6.125000                4.666667  \n",
       "2017-01-01 08:00:00                6.125000                4.666667  \n",
       "2017-01-01 09:00:00                6.125000                4.666667  \n",
       "2017-01-01 10:00:00                6.125000                4.666667  \n",
       "2017-01-01 11:00:00                6.125000                4.666667  \n",
       "2017-01-01 12:00:00                6.125000                4.666667  \n",
       "2017-01-01 13:00:00                6.125000                4.666667  \n",
       "2017-01-01 14:00:00                6.125000                4.666667  \n",
       "2017-01-01 15:00:00                6.125000                4.666667  \n",
       "2017-01-01 16:00:00                6.125000                4.666667  \n",
       "2017-01-01 17:00:00                6.125000                4.666667  \n",
       "2017-01-01 18:00:00                6.125000                4.666667  \n",
       "2017-01-01 19:00:00                6.125000                4.666667  \n",
       "2017-01-01 20:00:00                6.125000                4.666667  \n",
       "2017-01-01 21:00:00                6.125000                4.666667  \n",
       "2017-01-01 22:00:00                6.125000                4.666667  \n",
       "2017-01-01 23:00:00                6.125000                4.666667  \n",
       "2017-01-02 00:00:00                6.125000                4.666667  \n",
       "2017-01-02 01:00:00                5.875000                4.416667  \n",
       "2017-01-02 02:00:00                5.625000                4.125000  \n",
       "2017-01-02 03:00:00                5.458333                3.833333  \n",
       "2017-01-02 04:00:00                5.250000                3.541667  \n",
       "2017-01-02 05:00:00                5.041667                3.250000  \n",
       "2017-01-02 06:00:00                4.791667                2.958333  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_to_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "air_temperature           0\n",
       "dew_temperature           0\n",
       "day_hour                  0\n",
       "day_of_week               0\n",
       "air_temperature_ma_24H    0\n",
       "dew_temperature_ma_24H    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head().isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 0 --\n",
      "(17520, 6)\n",
      "-- 1 --\n",
      "(17183, 6)\n",
      "-- 2 --\n",
      "(17520, 6)\n",
      "-- 3 --\n",
      "(17520, 6)\n",
      "-- 4 --\n",
      "(17519, 6)\n",
      "-- 5 --\n",
      "(17124, 6)\n",
      "-- 6 --\n",
      "(17494, 6)\n",
      "-- 7 --\n",
      "(16368, 6)\n",
      "-- 8 --\n",
      "(17520, 6)\n",
      "-- 9 --\n",
      "(17191, 6)\n",
      "-- 10 --\n",
      "(17465, 6)\n",
      "-- 11 --\n",
      "(16368, 6)\n",
      "-- 12 --\n",
      "(17184, 6)\n",
      "-- 13 --\n",
      "(17520, 6)\n",
      "-- 14 --\n",
      "(17519, 6)\n",
      "-- 15 --\n",
      "(16734, 6)\n"
     ]
    }
   ],
   "source": [
    "for site, data in site_data.items():\n",
    "    print('-- {} --'.format(site))\n",
    "    print(data.shape)\n",
    "    #print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set(site_data[5].index)\n",
    "b = set(timestamps_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Timestamp('2017-01-01 00:00:00'),\n",
       " Timestamp('2017-08-08 04:00:00'),\n",
       " Timestamp('2017-08-08 05:00:00'),\n",
       " Timestamp('2017-08-08 06:00:00'),\n",
       " Timestamp('2017-08-08 07:00:00'),\n",
       " Timestamp('2017-08-08 08:00:00'),\n",
       " Timestamp('2017-08-08 09:00:00'),\n",
       " Timestamp('2017-08-08 10:00:00'),\n",
       " Timestamp('2017-08-08 11:00:00'),\n",
       " Timestamp('2017-08-08 12:00:00'),\n",
       " Timestamp('2017-08-08 13:00:00'),\n",
       " Timestamp('2017-08-08 14:00:00'),\n",
       " Timestamp('2017-08-08 15:00:00'),\n",
       " Timestamp('2017-08-08 16:00:00'),\n",
       " Timestamp('2017-08-08 17:00:00'),\n",
       " Timestamp('2017-08-08 18:00:00'),\n",
       " Timestamp('2017-08-08 19:00:00'),\n",
       " Timestamp('2017-08-08 20:00:00'),\n",
       " Timestamp('2017-08-08 21:00:00'),\n",
       " Timestamp('2017-08-08 22:00:00'),\n",
       " Timestamp('2017-08-08 23:00:00'),\n",
       " Timestamp('2017-08-09 00:00:00'),\n",
       " Timestamp('2017-08-09 01:00:00'),\n",
       " Timestamp('2017-08-09 02:00:00'),\n",
       " Timestamp('2017-08-09 03:00:00'),\n",
       " Timestamp('2018-04-11 14:00:00'),\n",
       " Timestamp('2018-04-11 15:00:00'),\n",
       " Timestamp('2018-04-11 16:00:00'),\n",
       " Timestamp('2018-04-11 17:00:00'),\n",
       " Timestamp('2018-04-11 18:00:00'),\n",
       " Timestamp('2018-04-11 19:00:00'),\n",
       " Timestamp('2018-04-11 20:00:00'),\n",
       " Timestamp('2018-04-11 21:00:00'),\n",
       " Timestamp('2018-04-11 22:00:00'),\n",
       " Timestamp('2018-04-11 23:00:00'),\n",
       " Timestamp('2018-04-12 00:00:00'),\n",
       " Timestamp('2018-04-12 01:00:00'),\n",
       " Timestamp('2018-04-12 02:00:00'),\n",
       " Timestamp('2018-04-12 03:00:00'),\n",
       " Timestamp('2018-04-12 04:00:00'),\n",
       " Timestamp('2018-04-12 05:00:00'),\n",
       " Timestamp('2018-04-12 06:00:00'),\n",
       " Timestamp('2018-04-12 07:00:00'),\n",
       " Timestamp('2018-04-12 08:00:00'),\n",
       " Timestamp('2018-04-12 09:00:00'),\n",
       " Timestamp('2018-04-12 10:00:00'),\n",
       " Timestamp('2018-04-12 11:00:00'),\n",
       " Timestamp('2018-04-12 12:00:00'),\n",
       " Timestamp('2018-04-12 13:00:00'),\n",
       " Timestamp('2018-04-12 14:00:00'),\n",
       " Timestamp('2018-04-12 15:00:00'),\n",
       " Timestamp('2018-04-12 16:00:00'),\n",
       " Timestamp('2018-04-12 17:00:00'),\n",
       " Timestamp('2018-04-12 18:00:00'),\n",
       " Timestamp('2018-07-08 18:00:00'),\n",
       " Timestamp('2018-07-08 19:00:00'),\n",
       " Timestamp('2018-07-08 20:00:00'),\n",
       " Timestamp('2018-07-08 21:00:00'),\n",
       " Timestamp('2018-07-08 22:00:00'),\n",
       " Timestamp('2018-07-08 23:00:00'),\n",
       " Timestamp('2018-07-09 00:00:00'),\n",
       " Timestamp('2018-07-09 01:00:00'),\n",
       " Timestamp('2018-07-09 02:00:00'),\n",
       " Timestamp('2018-07-09 03:00:00'),\n",
       " Timestamp('2018-07-09 04:00:00'),\n",
       " Timestamp('2018-07-09 05:00:00'),\n",
       " Timestamp('2018-07-09 06:00:00'),\n",
       " Timestamp('2018-07-09 07:00:00'),\n",
       " Timestamp('2018-07-09 08:00:00'),\n",
       " Timestamp('2018-07-09 09:00:00'),\n",
       " Timestamp('2018-07-09 10:00:00'),\n",
       " Timestamp('2018-07-09 11:00:00'),\n",
       " Timestamp('2018-07-09 12:00:00'),\n",
       " Timestamp('2018-07-09 13:00:00'),\n",
       " Timestamp('2018-07-09 14:00:00'),\n",
       " Timestamp('2018-07-09 15:00:00'),\n",
       " Timestamp('2018-07-09 16:00:00'),\n",
       " Timestamp('2018-07-09 17:00:00'),\n",
       " Timestamp('2018-09-15 20:00:00'),\n",
       " Timestamp('2018-09-15 21:00:00'),\n",
       " Timestamp('2018-09-15 22:00:00'),\n",
       " Timestamp('2018-09-15 23:00:00'),\n",
       " Timestamp('2018-09-16 00:00:00'),\n",
       " Timestamp('2018-09-16 01:00:00'),\n",
       " Timestamp('2018-09-16 02:00:00'),\n",
       " Timestamp('2018-09-16 03:00:00'),\n",
       " Timestamp('2018-09-16 04:00:00'),\n",
       " Timestamp('2018-09-16 05:00:00'),\n",
       " Timestamp('2018-09-16 06:00:00'),\n",
       " Timestamp('2018-09-16 07:00:00'),\n",
       " Timestamp('2018-09-16 08:00:00'),\n",
       " Timestamp('2018-09-16 09:00:00'),\n",
       " Timestamp('2018-09-16 10:00:00'),\n",
       " Timestamp('2018-09-16 11:00:00'),\n",
       " Timestamp('2018-09-16 12:00:00'),\n",
       " Timestamp('2018-09-16 13:00:00'),\n",
       " Timestamp('2018-09-16 14:00:00'),\n",
       " Timestamp('2018-09-16 15:00:00'),\n",
       " Timestamp('2018-09-16 16:00:00'),\n",
       " Timestamp('2018-09-16 17:00:00'),\n",
       " Timestamp('2018-09-16 18:00:00'),\n",
       " Timestamp('2018-09-16 19:00:00'),\n",
       " Timestamp('2018-09-16 20:00:00'),\n",
       " Timestamp('2018-09-16 21:00:00'),\n",
       " Timestamp('2018-09-16 22:00:00'),\n",
       " Timestamp('2018-09-16 23:00:00'),\n",
       " Timestamp('2018-09-17 00:00:00'),\n",
       " Timestamp('2018-09-17 01:00:00'),\n",
       " Timestamp('2018-09-17 06:00:00'),\n",
       " Timestamp('2018-09-17 07:00:00'),\n",
       " Timestamp('2018-09-17 08:00:00'),\n",
       " Timestamp('2018-09-17 09:00:00'),\n",
       " Timestamp('2018-09-17 10:00:00'),\n",
       " Timestamp('2018-09-17 11:00:00'),\n",
       " Timestamp('2018-09-17 12:00:00'),\n",
       " Timestamp('2018-09-17 13:00:00'),\n",
       " Timestamp('2018-09-17 14:00:00'),\n",
       " Timestamp('2018-09-17 15:00:00'),\n",
       " Timestamp('2018-09-17 16:00:00'),\n",
       " Timestamp('2018-09-17 17:00:00'),\n",
       " Timestamp('2018-09-17 18:00:00'),\n",
       " Timestamp('2018-09-17 19:00:00'),\n",
       " Timestamp('2018-09-17 20:00:00'),\n",
       " Timestamp('2018-09-17 21:00:00'),\n",
       " Timestamp('2018-09-17 22:00:00'),\n",
       " Timestamp('2018-09-17 23:00:00'),\n",
       " Timestamp('2018-09-18 00:00:00'),\n",
       " Timestamp('2018-09-18 01:00:00'),\n",
       " Timestamp('2018-09-18 02:00:00'),\n",
       " Timestamp('2018-09-18 03:00:00'),\n",
       " Timestamp('2018-09-18 04:00:00'),\n",
       " Timestamp('2018-09-18 05:00:00'),\n",
       " Timestamp('2018-09-18 06:00:00'),\n",
       " Timestamp('2018-09-18 07:00:00'),\n",
       " Timestamp('2018-09-18 08:00:00'),\n",
       " Timestamp('2018-09-18 09:00:00'),\n",
       " Timestamp('2018-09-18 10:00:00'),\n",
       " Timestamp('2018-09-18 11:00:00'),\n",
       " Timestamp('2018-09-18 12:00:00'),\n",
       " Timestamp('2018-09-18 13:00:00'),\n",
       " Timestamp('2018-09-18 14:00:00'),\n",
       " Timestamp('2018-09-18 15:00:00'),\n",
       " Timestamp('2018-09-18 16:00:00'),\n",
       " Timestamp('2018-09-18 17:00:00'),\n",
       " Timestamp('2018-09-18 18:00:00'),\n",
       " Timestamp('2018-09-18 19:00:00'),\n",
       " Timestamp('2018-09-18 20:00:00'),\n",
       " Timestamp('2018-09-18 21:00:00'),\n",
       " Timestamp('2018-09-18 22:00:00'),\n",
       " Timestamp('2018-09-18 23:00:00'),\n",
       " Timestamp('2018-09-19 00:00:00'),\n",
       " Timestamp('2018-09-19 01:00:00'),\n",
       " Timestamp('2018-09-19 02:00:00'),\n",
       " Timestamp('2018-09-19 03:00:00'),\n",
       " Timestamp('2018-09-19 04:00:00'),\n",
       " Timestamp('2018-09-19 05:00:00'),\n",
       " Timestamp('2018-09-19 06:00:00'),\n",
       " Timestamp('2018-09-19 07:00:00'),\n",
       " Timestamp('2018-09-19 08:00:00'),\n",
       " Timestamp('2018-09-19 09:00:00'),\n",
       " Timestamp('2018-09-20 08:00:00'),\n",
       " Timestamp('2018-09-20 09:00:00'),\n",
       " Timestamp('2018-09-20 10:00:00'),\n",
       " Timestamp('2018-09-20 11:00:00'),\n",
       " Timestamp('2018-09-20 12:00:00'),\n",
       " Timestamp('2018-09-20 13:00:00'),\n",
       " Timestamp('2018-09-20 14:00:00'),\n",
       " Timestamp('2018-09-20 15:00:00'),\n",
       " Timestamp('2018-09-20 16:00:00'),\n",
       " Timestamp('2018-09-20 17:00:00'),\n",
       " Timestamp('2018-09-20 18:00:00'),\n",
       " Timestamp('2018-09-20 19:00:00'),\n",
       " Timestamp('2018-09-20 20:00:00'),\n",
       " Timestamp('2018-09-20 21:00:00'),\n",
       " Timestamp('2018-09-20 22:00:00'),\n",
       " Timestamp('2018-09-20 23:00:00'),\n",
       " Timestamp('2018-09-21 00:00:00'),\n",
       " Timestamp('2018-09-21 01:00:00'),\n",
       " Timestamp('2018-09-21 02:00:00'),\n",
       " Timestamp('2018-09-21 03:00:00'),\n",
       " Timestamp('2018-09-21 04:00:00'),\n",
       " Timestamp('2018-09-21 05:00:00'),\n",
       " Timestamp('2018-09-21 06:00:00'),\n",
       " Timestamp('2018-09-21 07:00:00'),\n",
       " Timestamp('2018-09-21 08:00:00'),\n",
       " Timestamp('2018-09-24 01:00:00'),\n",
       " Timestamp('2018-09-24 02:00:00'),\n",
       " Timestamp('2018-09-24 03:00:00'),\n",
       " Timestamp('2018-09-24 04:00:00'),\n",
       " Timestamp('2018-09-24 05:00:00'),\n",
       " Timestamp('2018-09-24 06:00:00'),\n",
       " Timestamp('2018-09-24 07:00:00'),\n",
       " Timestamp('2018-09-24 08:00:00'),\n",
       " Timestamp('2018-09-24 09:00:00'),\n",
       " Timestamp('2018-09-24 10:00:00'),\n",
       " Timestamp('2018-09-24 11:00:00'),\n",
       " Timestamp('2018-09-24 12:00:00'),\n",
       " Timestamp('2018-09-24 13:00:00'),\n",
       " Timestamp('2018-09-24 14:00:00'),\n",
       " Timestamp('2018-09-24 15:00:00'),\n",
       " Timestamp('2018-09-24 16:00:00'),\n",
       " Timestamp('2018-09-24 17:00:00'),\n",
       " Timestamp('2018-09-24 18:00:00'),\n",
       " Timestamp('2018-09-24 19:00:00'),\n",
       " Timestamp('2018-09-24 20:00:00'),\n",
       " Timestamp('2018-09-24 21:00:00'),\n",
       " Timestamp('2018-09-24 22:00:00'),\n",
       " Timestamp('2018-09-24 23:00:00'),\n",
       " Timestamp('2018-09-25 00:00:00'),\n",
       " Timestamp('2018-09-25 01:00:00'),\n",
       " Timestamp('2018-09-25 02:00:00'),\n",
       " Timestamp('2018-09-25 03:00:00'),\n",
       " Timestamp('2018-09-25 04:00:00'),\n",
       " Timestamp('2018-09-25 05:00:00'),\n",
       " Timestamp('2018-09-25 06:00:00'),\n",
       " Timestamp('2018-09-25 07:00:00'),\n",
       " Timestamp('2018-09-25 08:00:00'),\n",
       " Timestamp('2018-09-25 09:00:00'),\n",
       " Timestamp('2018-09-25 10:00:00'),\n",
       " Timestamp('2018-09-25 11:00:00'),\n",
       " Timestamp('2018-09-25 12:00:00'),\n",
       " Timestamp('2018-09-25 13:00:00'),\n",
       " Timestamp('2018-09-25 14:00:00'),\n",
       " Timestamp('2018-09-25 15:00:00'),\n",
       " Timestamp('2018-09-25 16:00:00'),\n",
       " Timestamp('2018-09-25 17:00:00'),\n",
       " Timestamp('2018-09-25 18:00:00'),\n",
       " Timestamp('2018-11-16 20:00:00'),\n",
       " Timestamp('2018-11-16 21:00:00'),\n",
       " Timestamp('2018-11-16 22:00:00'),\n",
       " Timestamp('2018-11-16 23:00:00'),\n",
       " Timestamp('2018-11-17 00:00:00'),\n",
       " Timestamp('2018-11-17 01:00:00'),\n",
       " Timestamp('2018-11-17 02:00:00'),\n",
       " Timestamp('2018-11-17 03:00:00'),\n",
       " Timestamp('2018-11-17 04:00:00'),\n",
       " Timestamp('2018-11-17 05:00:00'),\n",
       " Timestamp('2018-11-17 06:00:00'),\n",
       " Timestamp('2018-11-17 07:00:00'),\n",
       " Timestamp('2018-11-17 08:00:00'),\n",
       " Timestamp('2018-11-17 09:00:00'),\n",
       " Timestamp('2018-11-17 10:00:00'),\n",
       " Timestamp('2018-11-17 11:00:00'),\n",
       " Timestamp('2018-11-17 12:00:00'),\n",
       " Timestamp('2018-11-17 13:00:00'),\n",
       " Timestamp('2018-11-17 14:00:00'),\n",
       " Timestamp('2018-11-17 15:00:00'),\n",
       " Timestamp('2018-11-17 16:00:00'),\n",
       " Timestamp('2018-11-17 17:00:00'),\n",
       " Timestamp('2018-11-17 18:00:00'),\n",
       " Timestamp('2018-11-17 19:00:00'),\n",
       " Timestamp('2018-11-17 20:00:00'),\n",
       " Timestamp('2018-11-17 21:00:00'),\n",
       " Timestamp('2018-11-17 22:00:00'),\n",
       " Timestamp('2018-11-17 23:00:00'),\n",
       " Timestamp('2018-11-18 00:00:00'),\n",
       " Timestamp('2018-11-18 01:00:00'),\n",
       " Timestamp('2018-11-18 02:00:00'),\n",
       " Timestamp('2018-11-18 03:00:00'),\n",
       " Timestamp('2018-11-18 04:00:00'),\n",
       " Timestamp('2018-11-18 05:00:00'),\n",
       " Timestamp('2018-11-18 06:00:00'),\n",
       " Timestamp('2018-11-18 07:00:00'),\n",
       " Timestamp('2018-11-18 08:00:00'),\n",
       " Timestamp('2018-11-18 09:00:00'),\n",
       " Timestamp('2018-11-18 10:00:00'),\n",
       " Timestamp('2018-11-18 11:00:00'),\n",
       " Timestamp('2018-11-18 12:00:00'),\n",
       " Timestamp('2018-11-18 13:00:00'),\n",
       " Timestamp('2018-11-18 14:00:00'),\n",
       " Timestamp('2018-11-18 15:00:00'),\n",
       " Timestamp('2018-11-18 16:00:00'),\n",
       " Timestamp('2018-11-18 17:00:00'),\n",
       " Timestamp('2018-11-18 18:00:00'),\n",
       " Timestamp('2018-11-18 19:00:00'),\n",
       " Timestamp('2018-11-18 20:00:00'),\n",
       " Timestamp('2018-11-18 21:00:00'),\n",
       " Timestamp('2018-11-18 22:00:00'),\n",
       " Timestamp('2018-11-18 23:00:00'),\n",
       " Timestamp('2018-11-19 00:00:00'),\n",
       " Timestamp('2018-11-19 01:00:00'),\n",
       " Timestamp('2018-11-19 02:00:00'),\n",
       " Timestamp('2018-11-19 03:00:00'),\n",
       " Timestamp('2018-11-19 04:00:00'),\n",
       " Timestamp('2018-11-19 05:00:00'),\n",
       " Timestamp('2018-11-19 06:00:00'),\n",
       " Timestamp('2018-11-19 07:00:00'),\n",
       " Timestamp('2018-11-19 08:00:00'),\n",
       " Timestamp('2018-11-19 09:00:00'),\n",
       " Timestamp('2018-11-19 10:00:00'),\n",
       " Timestamp('2018-11-19 11:00:00'),\n",
       " Timestamp('2018-11-19 12:00:00'),\n",
       " Timestamp('2018-11-19 13:00:00'),\n",
       " Timestamp('2018-11-19 14:00:00'),\n",
       " Timestamp('2018-11-19 15:00:00'),\n",
       " Timestamp('2018-11-19 16:00:00'),\n",
       " Timestamp('2018-11-19 17:00:00'),\n",
       " Timestamp('2018-11-19 18:00:00'),\n",
       " Timestamp('2018-11-19 19:00:00'),\n",
       " Timestamp('2018-11-19 20:00:00'),\n",
       " Timestamp('2018-11-19 21:00:00'),\n",
       " Timestamp('2018-11-19 22:00:00'),\n",
       " Timestamp('2018-11-19 23:00:00'),\n",
       " Timestamp('2018-11-20 00:00:00'),\n",
       " Timestamp('2018-11-20 01:00:00'),\n",
       " Timestamp('2018-11-20 02:00:00'),\n",
       " Timestamp('2018-11-20 03:00:00'),\n",
       " Timestamp('2018-11-20 04:00:00'),\n",
       " Timestamp('2018-11-20 05:00:00'),\n",
       " Timestamp('2018-11-20 06:00:00'),\n",
       " Timestamp('2018-11-20 07:00:00'),\n",
       " Timestamp('2018-11-20 08:00:00'),\n",
       " Timestamp('2018-11-20 09:00:00'),\n",
       " Timestamp('2018-11-20 10:00:00'),\n",
       " Timestamp('2018-11-20 11:00:00'),\n",
       " Timestamp('2018-11-20 12:00:00'),\n",
       " Timestamp('2018-11-20 13:00:00'),\n",
       " Timestamp('2018-11-20 14:00:00'),\n",
       " Timestamp('2018-11-20 15:00:00'),\n",
       " Timestamp('2018-11-20 16:00:00'),\n",
       " Timestamp('2018-11-20 17:00:00'),\n",
       " Timestamp('2018-11-20 18:00:00'),\n",
       " Timestamp('2018-11-20 19:00:00'),\n",
       " Timestamp('2018-11-20 20:00:00'),\n",
       " Timestamp('2018-11-20 21:00:00'),\n",
       " Timestamp('2018-11-20 22:00:00'),\n",
       " Timestamp('2018-11-20 23:00:00'),\n",
       " Timestamp('2018-11-21 00:00:00'),\n",
       " Timestamp('2018-11-21 01:00:00'),\n",
       " Timestamp('2018-11-21 02:00:00'),\n",
       " Timestamp('2018-11-21 03:00:00'),\n",
       " Timestamp('2018-11-21 04:00:00'),\n",
       " Timestamp('2018-11-21 05:00:00'),\n",
       " Timestamp('2018-11-21 06:00:00'),\n",
       " Timestamp('2018-11-21 07:00:00'),\n",
       " Timestamp('2018-11-21 08:00:00'),\n",
       " Timestamp('2018-11-21 09:00:00'),\n",
       " Timestamp('2018-11-21 10:00:00'),\n",
       " Timestamp('2018-11-21 11:00:00'),\n",
       " Timestamp('2018-11-21 12:00:00'),\n",
       " Timestamp('2018-11-21 13:00:00'),\n",
       " Timestamp('2018-11-21 14:00:00'),\n",
       " Timestamp('2018-11-21 15:00:00'),\n",
       " Timestamp('2018-11-21 16:00:00'),\n",
       " Timestamp('2018-11-21 17:00:00'),\n",
       " Timestamp('2018-11-21 18:00:00'),\n",
       " Timestamp('2018-11-21 19:00:00'),\n",
       " Timestamp('2018-11-21 20:00:00'),\n",
       " Timestamp('2018-11-21 21:00:00'),\n",
       " Timestamp('2018-11-21 22:00:00'),\n",
       " Timestamp('2018-11-21 23:00:00'),\n",
       " Timestamp('2018-11-22 00:00:00'),\n",
       " Timestamp('2018-11-22 01:00:00'),\n",
       " Timestamp('2018-11-22 02:00:00'),\n",
       " Timestamp('2018-11-22 03:00:00'),\n",
       " Timestamp('2018-11-22 04:00:00'),\n",
       " Timestamp('2018-11-22 05:00:00'),\n",
       " Timestamp('2018-11-22 06:00:00'),\n",
       " Timestamp('2018-11-22 07:00:00'),\n",
       " Timestamp('2018-11-22 08:00:00'),\n",
       " Timestamp('2018-11-22 09:00:00'),\n",
       " Timestamp('2018-11-22 10:00:00'),\n",
       " Timestamp('2018-11-22 11:00:00'),\n",
       " Timestamp('2018-11-22 12:00:00'),\n",
       " Timestamp('2018-11-22 13:00:00'),\n",
       " Timestamp('2018-11-22 14:00:00'),\n",
       " Timestamp('2018-11-22 15:00:00'),\n",
       " Timestamp('2018-11-22 16:00:00'),\n",
       " Timestamp('2018-11-22 17:00:00'),\n",
       " Timestamp('2018-11-22 18:00:00'),\n",
       " Timestamp('2018-11-22 19:00:00'),\n",
       " Timestamp('2018-11-22 20:00:00'),\n",
       " Timestamp('2018-11-22 21:00:00'),\n",
       " Timestamp('2018-11-22 22:00:00'),\n",
       " Timestamp('2018-11-22 23:00:00'),\n",
       " Timestamp('2018-11-23 00:00:00'),\n",
       " Timestamp('2018-11-23 01:00:00'),\n",
       " Timestamp('2018-11-23 02:00:00'),\n",
       " Timestamp('2018-11-23 03:00:00'),\n",
       " Timestamp('2018-11-23 04:00:00'),\n",
       " Timestamp('2018-11-23 05:00:00'),\n",
       " Timestamp('2018-11-23 06:00:00'),\n",
       " Timestamp('2018-11-23 07:00:00'),\n",
       " Timestamp('2018-11-23 08:00:00'),\n",
       " Timestamp('2018-11-23 09:00:00'),\n",
       " Timestamp('2018-11-23 10:00:00'),\n",
       " Timestamp('2018-11-23 11:00:00'),\n",
       " Timestamp('2018-11-23 12:00:00'),\n",
       " Timestamp('2018-11-23 13:00:00'),\n",
       " Timestamp('2018-11-23 14:00:00'),\n",
       " Timestamp('2018-11-23 15:00:00'),\n",
       " Timestamp('2018-11-23 16:00:00'),\n",
       " Timestamp('2018-11-23 17:00:00'),\n",
       " Timestamp('2018-11-23 18:00:00'),\n",
       " Timestamp('2018-11-23 19:00:00'),\n",
       " Timestamp('2018-11-23 20:00:00')}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
