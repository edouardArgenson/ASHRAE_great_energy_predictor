{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted, column_or_1d\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from tscv import GapKFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to build and evalutate simple models based on mean meter readings (per day of week, per hour)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important and tricky point is how are we going to split the data between train and validation.<br>\n",
    "For time-serie data, usually we cannot do the usual random split, because of correlations.<br>\n",
    "Usually, some kind of walk-forward approach is used.<br>\n",
    "Here, we use hv-block cross validation : we keep a gap of unused data between train and validation, to avoid using correlated data between train and validation.<br>\n",
    "This method has been studied and described by Racine (2000) : http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.30.6748&rep=rep1&type=pdf<br>\n",
    "We used an open-source implementation that extends scikit-learn : http://www.zhengwenjie.net/tscv/<br>\n",
    "See notebook 'test_tscv_lib.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 8524 entries, 2016-01-02 00:00:00 to 2016-12-31 23:00:00\n",
      "Data columns (total 8 columns):\n",
      "day_of_week                     8524 non-null int64\n",
      "day_hour                        8524 non-null int64\n",
      "dew_temperature_ma_24H          8524 non-null float64\n",
      "air_temperature                 8524 non-null float64\n",
      "wind_speed_ma_24H               8524 non-null float64\n",
      "precip_depth_1_hr_ma_24H        8524 non-null float64\n",
      "sea_level_pressure_shift_10H    8524 non-null float64\n",
      "meter_reading                   8524 non-null float64\n",
      "dtypes: float64(6), int64(2)\n",
      "memory usage: 599.3 KB\n"
     ]
    }
   ],
   "source": [
    "filepath = '../../data/intermediate/experimentation_train_sets/'\n",
    "filename = 'train_b_1176_m_0_t_20200111_195028.csv'\n",
    "\n",
    "df_features = pd.read_csv(filepath + filename, parse_dates=['timestamp'], index_col=['timestamp'])\n",
    "df_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_hour</th>\n",
       "      <th>dew_temperature_ma_24H</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>wind_speed_ma_24H</th>\n",
       "      <th>precip_depth_1_hr_ma_24H</th>\n",
       "      <th>sea_level_pressure_shift_10H</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-02 00:00:00</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-10.120833</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>4.737500</td>\n",
       "      <td>-0.208333</td>\n",
       "      <td>1019.4</td>\n",
       "      <td>73.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02 01:00:00</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.979167</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>4.779167</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>1018.9</td>\n",
       "      <td>69.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02 02:00:00</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.887500</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>4.862500</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>1017.9</td>\n",
       "      <td>68.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02 03:00:00</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-9.816667</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>4.883333</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>1017.4</td>\n",
       "      <td>69.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02 04:00:00</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-9.766667</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>4.862500</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>1017.1</td>\n",
       "      <td>69.085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     day_of_week  day_hour  dew_temperature_ma_24H  \\\n",
       "timestamp                                                            \n",
       "2016-01-02 00:00:00            5         0              -10.120833   \n",
       "2016-01-02 01:00:00            5         1               -9.979167   \n",
       "2016-01-02 02:00:00            5         2               -9.887500   \n",
       "2016-01-02 03:00:00            5         3               -9.816667   \n",
       "2016-01-02 04:00:00            5         4               -9.766667   \n",
       "\n",
       "                     air_temperature  wind_speed_ma_24H  \\\n",
       "timestamp                                                 \n",
       "2016-01-02 00:00:00             -3.3           4.737500   \n",
       "2016-01-02 01:00:00             -3.9           4.779167   \n",
       "2016-01-02 02:00:00             -5.0           4.862500   \n",
       "2016-01-02 03:00:00             -5.6           4.883333   \n",
       "2016-01-02 04:00:00             -6.1           4.862500   \n",
       "\n",
       "                     precip_depth_1_hr_ma_24H  sea_level_pressure_shift_10H  \\\n",
       "timestamp                                                                     \n",
       "2016-01-02 00:00:00                 -0.208333                        1019.4   \n",
       "2016-01-02 01:00:00                 -0.166667                        1018.9   \n",
       "2016-01-02 02:00:00                 -0.125000                        1017.9   \n",
       "2016-01-02 03:00:00                 -0.083333                        1017.4   \n",
       "2016-01-02 04:00:00                 -0.083333                        1017.1   \n",
       "\n",
       "                     meter_reading  \n",
       "timestamp                           \n",
       "2016-01-02 00:00:00         73.866  \n",
       "2016-01-02 01:00:00         69.788  \n",
       "2016-01-02 02:00:00         68.563  \n",
       "2016-01-02 03:00:00         69.133  \n",
       "2016-01-02 04:00:00         69.085  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_meter.shape = (8524, 7), y_meter.shape = (8524,)\n"
     ]
    }
   ],
   "source": [
    "y_meter = df_features['meter_reading']\n",
    "X_meter = df_features.loc[:, df_features.columns != 'meter_reading']\n",
    "print('X_meter.shape = {}, y_meter.shape = {}'.format(X_meter.shape, y_meter.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GapKFold\n",
    "# gap ~ two weeks, train = 1 month (12 folds)\n",
    "\n",
    "gap = 24*7*2\n",
    "gap_kf = GapKFold(n_splits=12, gap_before=gap, gap_after=gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a mean value estimator.\n",
    "\n",
    "From https://github.com/scikit-learn-contrib/project-template/blob/master/skltemplate/_template.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check_array and check_X_y\n",
    "\n",
    "https://github.com/scikit-learn/scikit-learn/blob/e5698bde9/sklearn/utils/validation.py#L904"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually we don't need that because it already exists in sklearn, under the name 'dummyRegressor'\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10966881921925091"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(\n",
    "    estimator=DummyRegressor(strategy=\"mean\"),\n",
    "    X=X_meter,\n",
    "    y=y_meter,\n",
    "    scoring='neg_mean_squared_log_error',\n",
    "    cv=gap_kf).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10827571289521588"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(\n",
    "    estimator=DummyRegressor(strategy=\"median\"),\n",
    "    X=X_meter,\n",
    "    y=y_meter,\n",
    "    scoring='neg_mean_squared_log_error',\n",
    "    cv=gap_kf).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note : this is not the RMSLE metric defined for the competition, it is not in sklearn, we must implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's take the mean by hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanByCatEstimator(BaseEstimator):\n",
    "    \"\"\" A template estimator to be used as a reference implementation.\n",
    "    For more information regarding how to build your own estimator, read more\n",
    "    in the :ref:`User Guide <user_guide>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    demo_param : str, default='demo_param'\n",
    "        A parameter used for demonstation of how to pass and store paramters.\n",
    "    \"\"\"\n",
    "    def __init__(self, cat_column_idx=0, verbose=False):\n",
    "        self.verbose = verbose\n",
    "        self.cat_column_idx= cat_column_idx\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"A reference implementation of a fitting function.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        y : array-like, shape (n_samples,) or (n_samples, n_outputs)\n",
    "            The target values (class labels in classification, real numbers in\n",
    "            regression).\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        \n",
    "        X, y = check_X_y(X, y, accept_sparse=True)\n",
    "        \"\"\"Input validation for standard estimators.\n",
    "        Checks X and y for consistent length, enforces X to be 2D and y 1D. By\n",
    "        default, X is checked to be non-empty and containing only finite values.\n",
    "        Standard input checks are also applied to y, such as checking that y\n",
    "        does not have np.nan or np.inf targets. For multi-label y, set\n",
    "        multi_output=True to allow 2D and sparse y. If the dtype of X is\n",
    "        object, attempt converting to float, raising on failure.\n",
    "        \"\"\"\n",
    "        \n",
    "        if(self.cat_column_idx >= X.shape[1]):\n",
    "             raise ValueError(\"category column index should be < X.shape[1]\")\n",
    "        \n",
    "        categories = {}\n",
    "        self.means = {}\n",
    "        \n",
    "        self.mean = y.mean()\n",
    "        \n",
    "        for x_bin in np.unique(X[:, self.cat_column_idx]):\n",
    "            categories[x_bin] = []\n",
    "            \n",
    "        if self.verbose:    \n",
    "            print('categories : {}'.format(categories.keys()))\n",
    "            \n",
    "        for k in range(X.shape[0]):\n",
    "            categories[X[k, self.cat_column_idx]].append(y[k])\n",
    "        \n",
    "        for k, v in categories.items():\n",
    "            self.means[k] = np.array(v).mean()\n",
    "        \n",
    "        self.is_fitted_ = True\n",
    "        # `fit` should always return `self`\n",
    "        \n",
    "        if self.verbose:\n",
    "            for k, v in self.means.items():\n",
    "                print('({}, {})'.format(k, v))\n",
    "        \n",
    "        return self\n",
    "\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\" A reference implementation of a predicting function.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        Returns\n",
    "        -------\n",
    "        y : ndarray, shape (n_samples,)\n",
    "            Returns an array of ones.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        X = check_array(X, accept_sparse=True)\n",
    "        \"\"\"Input validation on an array, list, sparse matrix or similar.\n",
    "        By default, the input is checked to be a non-empty 2D array containing\n",
    "        only finite values. If the dtype of the array is object, attempt\n",
    "        converting to float, raising on failure.\"\"\"\n",
    "        \n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        for sample_cat in X[:, self.cat_column_idx]:\n",
    "            cat_mean = self.means.get(sample_cat)\n",
    "            if(cat_mean == None):\n",
    "                predictions.append(self.mean)\n",
    "            else:\n",
    "                predictions.append(cat_mean)\n",
    "            \n",
    "        \n",
    "        \n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_hour_col_idx = X_meter.columns.to_list().index('day_hour')\n",
    "\n",
    "myEst = MeanByCatEstimator(cat_column_idx=day_hour_col_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeanByCatEstimator(cat_column_idx=1, verbose=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myEst.fit(X_meter, y_meter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8524, 7)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_meter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  0  1  1  1  1  1  1]\n",
      " [ 1  3  1  1  1  1  1  1]\n",
      " [ 1  5  1  1  1  1  1  1]\n",
      " [ 1  6  1  1  1  1  1  1]\n",
      " [ 1  8  1  1  1  1  1  1]\n",
      " [ 1 10  1  1  1  1  1  1]\n",
      " [ 1 15  1  1  1  1  1  1]\n",
      " [ 1  2  1  1  1  1  1  1]\n",
      " [ 1  5  1  1  1  1  1  1]\n",
      " [ 1  7  1  1  1  1  1  1]\n",
      " [ 1 22  1  1  1  1  1  1]\n",
      " [ 1 27  1  1  1  1  1  1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 85.67500568,  76.00959687,  75.88157423,  76.47674302,\n",
       "       101.06289014, 134.37695014, 147.80155211,  77.40017938,\n",
       "        75.88157423,  89.0337563 , 108.73477222, 112.84224061])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_6 = np.array([0,3,5,6,8,10,15,2,5,7,22,27])\n",
    "\n",
    "t = np.transpose(np.array([\n",
    "    np.ones(12, dtype=np.int64),\n",
    "    t_6,\n",
    "    np.ones(12, dtype=np.int64), \n",
    "    np.ones(12, dtype=np.int64),\n",
    "    np.ones(12, dtype=np.int64),\n",
    "    np.ones(12, dtype=np.int64),\n",
    "    np.ones(12, dtype=np.int64),\n",
    "    np.ones(12, dtype=np.int64)\n",
    "]))\n",
    "\n",
    "\n",
    "print(t)\n",
    "\n",
    "myEst.predict(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04666112104598815"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_hour_col_idx = X_meter.columns.to_list().index('day_hour')\n",
    "\n",
    "cross_val_score(\n",
    "    estimator=MeanByCatEstimator(cat_column_idx=day_hour_col_idx),\n",
    "    X=X_meter,\n",
    "    y=y_meter,\n",
    "    scoring='neg_mean_squared_log_error',\n",
    "    cv=gap_kf).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanByMultiCatEstimator(BaseEstimator):\n",
    "    \"\"\" A template estimator to be used as a reference implementation.\n",
    "    For more information regarding how to build your own estimator, read more\n",
    "    in the :ref:`User Guide <user_guide>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    demo_param : str, default='demo_param'\n",
    "        A parameter used for demonstation of how to pass and store paramters.\n",
    "    \"\"\"\n",
    "    def __init__(self, cat_column_indexes=[0], verbose=False):\n",
    "        self.verbose = verbose\n",
    "        self.cat_column_indexes = cat_column_indexes\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"A reference implementation of a fitting function.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        y : array-like, shape (n_samples,) or (n_samples, n_outputs)\n",
    "            The target values (class labels in classification, real numbers in\n",
    "            regression).\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        \n",
    "        X, y = check_X_y(X, y, accept_sparse=True)\n",
    "        \"\"\"Input validation for standard estimators.\n",
    "        Checks X and y for consistent length, enforces X to be 2D and y 1D. By\n",
    "        default, X is checked to be non-empty and containing only finite values.\n",
    "        Standard input checks are also applied to y, such as checking that y\n",
    "        does not have np.nan or np.inf targets. For multi-label y, set\n",
    "        multi_output=True to allow 2D and sparse y. If the dtype of X is\n",
    "        object, attempt converting to float, raising on failure.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        cat_columns = []\n",
    "        \n",
    "        for col_idx in self.cat_column_indexes:\n",
    "            if(col_idx >= X.shape[1]):\n",
    "                raise ValueError(\"category column indexes should be < X.shape[1]\")\n",
    "            cat_columns.append(X[:, col_idx])\n",
    "            \n",
    "        cat_tuples = set(zip(*cat_columns))\n",
    "        \n",
    "        categories = {}\n",
    "        self.means = {}\n",
    "        \n",
    "        self.mean = y.mean()\n",
    "        \n",
    "        for x_bin in cat_tuples:\n",
    "            categories[x_bin] = []\n",
    "            \n",
    "        if self.verbose:    \n",
    "            print('categories : {}'.format(categories.keys()))\n",
    "            \n",
    "        for k in range(X.shape[0]):\n",
    "            sample_bin = tuple(X[k, self.cat_column_indexes])\n",
    "            categories[sample_bin].append(y[k])\n",
    "        \n",
    "        for k, v in categories.items():\n",
    "            self.means[k] = np.array(v).mean()\n",
    "        \n",
    "        self.is_fitted_ = True\n",
    "        # `fit` should always return `self`\n",
    "        \n",
    "        if self.verbose:\n",
    "            for k, v in self.means.items():\n",
    "                print('({}, {})'.format(k, v))\n",
    "        \n",
    "        return self\n",
    "\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\" A reference implementation of a predicting function.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        Returns\n",
    "        -------\n",
    "        y : ndarray, shape (n_samples,)\n",
    "            Returns an array of ones.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        X = check_array(X, accept_sparse=True)\n",
    "        \"\"\"Input validation on an array, list, sparse matrix or similar.\n",
    "        By default, the input is checked to be a non-empty 2D array containing\n",
    "        only finite values. If the dtype of the array is object, attempt\n",
    "        converting to float, raising on failure.\"\"\"\n",
    "        \n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        \n",
    "        cat_columns=[]\n",
    "        for col in self.cat_column_indexes:\n",
    "            cat_columns.append(X[:, col])\n",
    "            \n",
    "        cat_tuples = list(zip(*cat_columns))\n",
    "        \n",
    "        \n",
    "        \n",
    "        for sample_cat in cat_tuples:\n",
    "            cat_mean = self.means.get(sample_cat)\n",
    "            if(cat_mean == None):\n",
    "                predictions.append(self.mean)\n",
    "            else:\n",
    "                predictions.append(cat_mean)\n",
    "            \n",
    "        \n",
    "        \n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['day_of_week', 'day_hour', 'dew_temperature_ma_24H', 'air_temperature',\n",
       "       'wind_speed_ma_24H', 'precip_depth_1_hr_ma_24H',\n",
       "       'sea_level_pressure_shift_10H'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_meter.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.026519821080049997"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(\n",
    "    estimator=MeanByMultiCatEstimator([0,1]),\n",
    "    X=X_meter,\n",
    "    y=y_meter,\n",
    "    scoring='neg_mean_squared_log_error',\n",
    "    cv=gap_kf).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
